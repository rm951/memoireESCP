{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the data from INSEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "url = \"https://www.insee.fr/fr/statistiques/fichier/4648335/bdf2017fe_csv.zip\"\n",
    "filename = \"bdf2017fe_csv.zip\"\n",
    "\n",
    "# Define the destination directory\n",
    "dest_dir = 'already_downloaded_data'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "# Join the destination directory with the filename to create the full destination path\n",
    "dest_path = os.path.join(dest_dir, filename)\n",
    "\n",
    "# Download the file and save it to the destination path\n",
    "urllib.request.urlretrieve(url, dest_path)\n",
    "\n",
    "# Extract the contents of the zip file to the destination directory\n",
    "with zipfile.ZipFile(dest_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dest_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_filename = \"tf106.csv\"\n",
    "csv_filepath = os.path.join(dest_dir, csv_filename)\n",
    "\n",
    "df = pd.read_csv(csv_filepath, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['DECUC'] == 'TOT'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering values with exactly 4 characters, corresponding to ECOICOP classes\n",
    "df = df.loc[df['NOMENCLATURE'].str.len() == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the \"NOMENCLATURE\" column to \"FCOICOP\"\n",
    "df = df.rename(columns={'NOMENCLATURE': 'FCOICOP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out rows where the \"FCOIC\" value starts with \"13\"\n",
    "df = df.loc[~df['FCOICOP'].str.startswith('13')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the second csv file with the \"FCOICOP\" column\n",
    "df2 = pd.read_csv('Nomenclature_classes_to_special_aggregates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two dataframes on the \"FCOICOP\" column\n",
    "merged_df = pd.merge(df, df2, on='FCOICOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the sum of \"CONSO\" for each unique value in \"DECUC\" column\n",
    "sum_by_decuc = merged_df.groupby('DECUC')['CONSO'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new column \"PROP\" with the percentage of each row relative to the sum for each unique value in \"DECUC\" column\n",
    "merged_df['PROP'] = merged_df['CONSO'] / merged_df['DECUC'].map(sum_by_decuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# group the merged dataframe by \"AGGREGATE\" and \"DECUC\" and sum the values in the \"PROP\" column for each group\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m grouped_df \u001b[39m=\u001b[39m merged_df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mAGGREGATE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDECUC\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mPROP\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      7\u001b[0m \u001b[39m# create a new column \"DECUC_SORTED\" with values sorted in a specific order\u001b[39;00m\n\u001b[0;32m      8\u001b[0m decuc_order \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m6\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m7\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m9\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m10\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# group the merged dataframe by \"AGGREGATE\" and \"DECUC\" and sum the values in the \"PROP\" column for each group\n",
    "grouped_df = merged_df.groupby(['AGGREGATE', 'DECUC'])['PROP'].sum().reset_index()\n",
    "\n",
    "\n",
    "# create a new column \"DECUC_SORTED\" with values sorted in a specific order\n",
    "decuc_order = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "grouped_df['DECUC_SORTED'] = pd.Categorical(grouped_df['DECUC'], categories=decuc_order, ordered=True)\n",
    "\n",
    "# pivot the dataframe to create a table where each row represents a DECUC, and each column represents an AGGREGATE with the values in the \"PROP\" column\n",
    "pivoted_df = grouped_df.pivot(index='DECUC_SORTED', columns='AGGREGATE', values='PROP').fillna(0)\n",
    "\n",
    "\n",
    "# calculate the cumulative sum of the values in the pivoted dataframe\n",
    "cumulative_df = pivoted_df.cumsum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create a stacked bar chart with a bar for each DECUC and bars of colors with sizes proportional to PROP for each AGGREGATE\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, (colname, color) in enumerate(zip(pivoted_df.columns, ['blue', 'green', 'red', 'purple'])):\n",
    "    ax.bar(pivoted_df.index, pivoted_df[colname], bottom=cumulative_df.iloc[:, i-1] if i>0 else None, width=0.5, color=color, alpha=0.8, label=colname)\n",
    "\n",
    "# change the legend labels using a dictionary\n",
    "legend_labels = {'FOOD': 'Food', 'IGD': 'Industrial goods', 'SERV': 'Services', 'NRG': 'Energy'}\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [legend_labels[label] if label in legend_labels else label for label in labels]\n",
    "ax.legend(handles, new_labels, title=\"Components\")\n",
    "\n",
    "ax.set_xlabel(\"Deciles\")\n",
    "ax.set_ylabel(\"Proportion of consumption by component\")\n",
    "\n",
    "plt.title(\"Proportion of annual household expenditures in France by deciles in 2017\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
